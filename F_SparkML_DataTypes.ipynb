{"cells":[{"cell_type":"markdown","source":["# Data Types - RDD-based API\n\n> https://spark.apache.org/docs/latest/mllib-data-types.html#local-vector"],"metadata":{}},{"cell_type":"markdown","source":["## local vectors: dense and sparse.\n\n- A dense vector \nis backed by a double array representing its entry values\n\n- sparse vector i\ns backed by two parallel arrays: indices and values. \n\nFor example, a vector (1.0, 0.0, 3.0) can be represented in dense format as [1.0, 0.0, 3.0] or in sparse format as (3, [0, 2], [1.0, 3.0]), where 3 is the size of the vector."],"metadata":{}},{"cell_type":"markdown","source":["### dense vector \n- NumPy’s array\n- Python’s list, e.g., [1, 2, 3]"],"metadata":{}},{"cell_type":"code","source":["import numpy as np\nimport scipy.sparse as sps\nfrom pyspark.mllib.linalg import Vectors\n\n# Use a NumPy array as a dense vector.\ndv1 = np.array([1.0, 0.0, 3.0])\n# Use a Python list as a dense vector.\ndv2 = [1.0, 0.0, 3.0]\n\nprint(dv1)\nprint(dv2)\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["### Sparse Vector\n\n- MLlib’s SparseVector.\n- SciPy’s csc_matrix with a single column"],"metadata":{}},{"cell_type":"code","source":["# Create a SparseVector.\nsv1 = Vectors.sparse(3, [0, 2], [1.0, 3.0])\n# Use a single-column SciPy csc_matrix as a sparse vector.\nsv2 = sps.csc_matrix((np.array([1.0, 3.0]), np.array([0, 2]), np.array([0, 2])), shape=(3, 1))\n\nprint(sv1)\nprint(sv2)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Labeled point\n\n- A labeled point is a local vector, either dense or sparse, associated with a label/response. \n- In MLlib, labeled points are used in supervised learning algorithms. \n- For binary classification, a label should be either 0 (negative) or 1 (positive). \n- For multiclass classification, labels should be class indices starting from zero: 0, 1, 2, ...."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.linalg import SparseVector\nfrom pyspark.mllib.regression import LabeledPoint\n\n# Create a labeled point with a positive label and a dense feature vector.\npos = LabeledPoint(1.0, [1.0, 0.0, 3.0])\n\n# Create a labeled point with a negative label and a sparse feature vector.\nneg = LabeledPoint(0.0, SparseVector(3, [0, 2], [1.0, 3.0]))\n\nprint(pos)\nprint(neg)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Local matrix\n- A local matrix has integer-typed row and column indices and double-typed values, stored on a single machine. \n- MLlib supports :\n> - dense matrices, whose entry values are stored in a single double array in column-major order, and \n> - sparse matrices, whose non-zero entry values are stored in the Compressed Sparse Column (CSC) format in column-major order. \n- For example, the following dense matrix\n> - [1.0 2.0\n> - 3.0 4.0\n> - 5.0 6.0]\n\nis stored in a one-dimensional array [1.0, 3.0, 5.0, 2.0, 4.0, 6.0] with the matrix size (3, 2)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.linalg import Matrix, Matrices\n\n# Create a dense matrix ((1.0, 2.0), (3.0, 4.0), (5.0, 6.0))\ndm2 = Matrices.dense(3, 2, [1, 2, 3, 4, 5, 6])\nprint(dm2)\n\n# Create a sparse matrix ((9.0, 0.0), (0.0, 8.0), (0.0, 6.0))\nsm = Matrices.sparse(3, 2, [0, 1, 3], [0, 2, 1], [9, 6, 8])\nprint(sm)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["##Distributed matrix\n- A distributed matrix has long-typed row and column indices and double-typed values, stored distributively in one or more RDDs. \n- Converting a distributed matrix to a different format may require a global shuffle, which is quite expensive. \n- Four types of distributed matrices have been implemented so far.\n> - 1. The basic type is called RowMatrix. A RowMatrix is a row-oriented distributed matrix without meaningful row indices, e.g., a collection of feature vectors. It is backed by an RDD of its rows, where each row is a local vector. We assume that the number of columns is not huge for a RowMatrix so that a single local vector can be reasonably communicated to the driver and can also be stored / operated on using a single node. \n> - 2 . An IndexedRowMatrix is similar to a RowMatrix but with row indices, which can be used for identifying rows and executing joins. \n> - 3 . A CoordinateMatrix is a distributed matrix stored in coordinate list (COO) format, backed by an RDD of its entries. \n> - 4 . A BlockMatrix is a distributed matrix backed by an RDD of MatrixBlock which is a tuple of (Int, Int, Matrix)."],"metadata":{}},{"cell_type":"markdown","source":["## RowMatrix\n- A RowMatrix is a row-oriented distributed matrix without meaningful row indices, backed by an RDD of its rows, where each row is a local vector. \n- Since each row is represented by a local vector, the number of columns is limited by the integer range but it should be much smaller in practice."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.linalg.distributed import RowMatrix\n\n# Create an RDD of vectors.\nrows = sc.parallelize([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n\n# Create a RowMatrix from an RDD of vectors.\nmat = RowMatrix(rows)\n\n# Get its size.\nm = mat.numRows()  # 4\nn = mat.numCols()  # 3\n\n# Get the rows as an RDD of vectors again.\nrowsRDD = mat.rows\n\ndef g(x):\n      print x\n    \nrowsRDD.foreach(g)\n\n      "],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["## IndexedRowMatrix\n- An IndexedRowMatrix is similar to a RowMatrix but with meaningful row indices. \n- It is backed by an RDD of indexed rows, so that each row is represented by its index (long-typed) and a local vector."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n\n# Create an RDD of indexed rows.\n#   - This can be done explicitly with the IndexedRow class:\nindexedRows = sc.parallelize([IndexedRow(0, [1, 2, 3]),\n                              IndexedRow(1, [4, 5, 6]),\n                              IndexedRow(2, [7, 8, 9]),\n                              IndexedRow(3, [10, 11, 12])])\n#   - or by using (long, vector) tuples:\nindexedRows = sc.parallelize([(0, [1, 2, 3]), (1, [4, 5, 6]),\n                              (2, [7, 8, 9]), (3, [10, 11, 12])])\n\n# Create an IndexedRowMatrix from an RDD of IndexedRows.\nmat = IndexedRowMatrix(indexedRows)\n\n# Get its size.\nm = mat.numRows()  # 4\nn = mat.numCols()  # 3\n\n# Get the rows as an RDD of IndexedRows.\nrowsRDD = mat.rows\n\n# Convert to a RowMatrix by dropping the row indices.\nrowMat = mat.toRowMatrix()\nprint(rowMat)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["## CoordinateMatrix\n- A CoordinateMatrix is a distributed matrix backed by an RDD of its entries. \n- Each entry is a tuple of (i: Long, j: Long, value: Double), where i is the row index, j is the column index, and value is the entry value. \n- A CoordinateMatrix should be used only when both dimensions of the matrix are huge and the matrix is very sparse."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.linalg.distributed import CoordinateMatrix, MatrixEntry\n\n# Create an RDD of coordinate entries.\n#   - This can be done explicitly with the MatrixEntry class:\nentries = sc.parallelize([MatrixEntry(0, 0, 1.2), MatrixEntry(1, 0, 2.1), MatrixEntry(6, 1, 3.7)])\n#   - or using (long, long, float) tuples:\nentries = sc.parallelize([(0, 0, 1.2), (1, 0, 2.1), (2, 1, 3.7)])\n\n# Create an CoordinateMatrix from an RDD of MatrixEntries.\nmat = CoordinateMatrix(entries)\n\n# Get its size.\nm = mat.numRows()  # 3\nn = mat.numCols()  # 2\n\n# Get the entries as an RDD of MatrixEntries.\nentriesRDD = mat.entries\n\n# Convert to a RowMatrix.\nrowMat = mat.toRowMatrix()\n\n# Convert to an IndexedRowMatrix.\nindexedRowMat = mat.toIndexedRowMatrix()\n\n# Convert to a BlockMatrix.\nblockMat = mat.toBlockMatrix()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["## BlockMatrix\n- A BlockMatrix is a distributed matrix backed by an RDD of MatrixBlocks, \n- where a MatrixBlock is a tuple of ((Int, Int), Matrix), where the (Int, Int) is the index of the block, and Matrix is the sub-matrix at the given index with size rowsPerBlock x colsPerBlock. \n- BlockMatrix supports methods such as add and multiply with another BlockMatrix. \n- BlockMatrix also has a helper function validate which can be used to check whether the BlockMatrix is set up properly."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.linalg import Matrices\nfrom pyspark.mllib.linalg.distributed import BlockMatrix\n\n# Create an RDD of sub-matrix blocks.\nblocks = sc.parallelize([((0, 0), Matrices.dense(3, 2, [1, 2, 3, 4, 5, 6])),\n                         ((1, 0), Matrices.dense(3, 2, [7, 8, 9, 10, 11, 12]))])\n\n# Create a BlockMatrix from an RDD of sub-matrix blocks.\nmat = BlockMatrix(blocks, 3, 2)\n\n# Get its size.\nm = mat.numRows()  # 6\nn = mat.numCols()  # 2\n\n# Get the blocks as an RDD of sub-matrix blocks.\nblocksRDD = mat.blocks\n\n# Convert to a LocalMatrix.\nlocalMat = mat.toLocalMatrix()\n\n# Convert to an IndexedRowMatrix.\nindexedRowMat = mat.toIndexedRowMatrix()\n\n# Convert to a CoordinateMatrix.\ncoordinateMat = mat.toCoordinateMatrix()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"F_SparkML_DataTypes","notebookId":2926114545407441},"nbformat":4,"nbformat_minor":0}
