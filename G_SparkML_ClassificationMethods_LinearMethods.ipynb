{"cells":[{"cell_type":"markdown","source":["# Linear Methods\nhttps://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#logistic-regression"],"metadata":{}},{"cell_type":"markdown","source":["## Linear Support Vector Machines (SVMs)\n\n- The linear SVM is a standard method for large-scale classification tasks. \n-"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.classification import SVMWithSGD, SVMModel\nfrom pyspark.mllib.regression import LabeledPoint\nimport urllib2\n\n# Load and parse the data\ndef parsePoint(line):\n    values = [float(x) for x in line.split(' ')]\n    return LabeledPoint(values[0], values[1:])\n###\nfileURL = \"https://raw.githubusercontent.com/cloudera/spark/master/mllib/data/sample_svm_data.txt\"\nfileLocation = \"/tmp/sample_svm_data.txt\"\nresult = dbutils.fs.rm(fileLocation)\ndbutils.fs.put(fileLocation, urllib2.urlopen(fileURL).read())\n###\n\ndata = sc.textFile(fileLocation)\n#print data.collect()\nparsedData = data.map(parsePoint)\n#print parsedData.collect()\n\n# Build the model\nmodel = SVMWithSGD.train(parsedData, iterations=100)\n\n# Evaluating the model on training data\nlabelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\ntrainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\nprint(\"Training Error = \" + str(trainErr))\n\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# empth the dir if exist\n%fs rm target/tmp/pythonSVMWithSGDModel/"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Save and load model\nresult = dbutils.fs.rm(\"target/tmp/pythonSVMWithSGDModel/*\")\nmodel.save(sc, \"target/tmp/pythonSVMWithSGDModel\")\nsameModel = SVMModel.load(sc, \"target/tmp/pythonSVMWithSGDModel\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%fs ls target/tmp/pythonSVMWithSGDModel"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Logistic regression\n- Logistic regression is widely used to predict a binary response\n- The following example shows how to load a sample dataset, build Logistic Regression model, and make predictions with the resulting model to compute the training error."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\nfrom pyspark.mllib.regression import LabeledPoint\n\n# Load and parse the data\ndef parsePoint(line):\n    values = [float(x) for x in line.split(' ')]\n    return LabeledPoint(values[0], values[1:])\n  \n###\nfileURL = \"https://raw.githubusercontent.com/cloudera/spark/master/mllib/data/sample_svm_data.txt\"\nfileLocation = \"/tmp/sample_svm_data.txt\"\nresult = dbutils.fs.rm(fileLocation)\ndbutils.fs.put(fileLocation, urllib2.urlopen(fileURL).read())\n###\n\n\ndata = sc.textFile(fileLocation)\nparsedData = data.map(parsePoint)\n\n# Build the model\nmodel = LogisticRegressionWithLBFGS.train(parsedData)\n\n# Evaluating the model on training data\nlabelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\ntrainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\nprint(\"Training Error = \" + str(trainErr))\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["\n# Save and load model\nmodel.save(sc, \"target/tmp/pythonLogisticRegressionWithLBFGSModel\")\nsameModel = LogisticRegressionModel.load(sc,\n                                         \"target/tmp/pythonLogisticRegressionWithLBFGSModel\")"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["## Regression\n- Linear least squares, Lasso, and ridge regression\n- Linear least squares is the most common formulation for regression problems. \n- The following example demonstrate how to load training data, parse it as an RDD of LabeledPoint. The example then uses LinearRegressionWithSGD to build a simple linear model to predict label values. \n- We compute the mean squared error at the end to evaluate goodness of fit."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel\n\n# Load and parse the data\ndef parsePoint(line):\n    values = [float(x) for x in line.replace(',', ' ').split(' ')]\n    return LabeledPoint(values[0], values[1:])\n\n###\nfileURL = \"https://raw.githubusercontent.com/cloudera/spark/master/mllib/data/sample_svm_data.txt\"\nfileLocation = \"/tmp/sample_svm_data.txt\"\nresult = dbutils.fs.rm(fileLocation)\ndbutils.fs.put(fileLocation, urllib2.urlopen(fileURL).read())\n###\n\ndata = sc.textFile(fileLocation)\nparsedData = data.map(parsePoint)\n\n# Build the model\nmodel = LinearRegressionWithSGD.train(parsedData, iterations=100, step=0.00000001)\n\n# Evaluate the model on training data\nvaluesAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\nMSE = valuesAndPreds \\\n    .map(lambda vp: (vp[0] - vp[1])**2) \\\n    .reduce(lambda x, y: x + y) / valuesAndPreds.count()\nprint(\"Mean Squared Error = \" + str(MSE))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Save and load model\nmodel.save(sc, \"target/tmp/pythonLinearRegressionWithSGDModel\")\nsameModel = LinearRegressionModel.load(sc, \"target/tmp/pythonLinearRegressionWithSGDModel\")"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Implementation (developer)\n- Behind the scene, spark.mllib implements a simple distributed version of stochastic gradient descent (SGD), building on the underlying gradient descent primitive (as described in the optimization section). \n- All provided algorithms take as input a regularization parameter (regParam) along with various parameters associated with stochastic gradient descent (stepSize, numIterations, miniBatchFraction). \n- For each of them, we support all three possible regularizations (none, L1 or L2).\n\n\n- For Logistic Regression, L-BFGS version is implemented under LogisticRegressionWithLBFGS, and this version supports both binary and multinomial Logistic Regression while SGD version only supports binary Logistic Regression. \n- However, L-BFGS version doesnâ€™t support L1 regularization but SGD one supports L1 regularization. \n- When L1 regularization is not required, L-BFGS version is strongly recommended since it converges faster and more accurately compared to SGD by approximating the inverse Hessian matrix using quasi-Newton method."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"G_SparkML_ClassificationMethods_LinearMethods","notebookId":4234575249910501},"nbformat":4,"nbformat_minor":0}
